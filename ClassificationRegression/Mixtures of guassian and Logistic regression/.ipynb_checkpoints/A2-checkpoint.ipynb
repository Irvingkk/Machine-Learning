{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "import csv\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readfile():\n",
    "    testData = []\n",
    "    testLabel= []\n",
    "    trainData = []\n",
    "    trainLabel= []\n",
    "    for i in range(1, 11):\n",
    "        filename1 = 'knn-dataset/trainData' + str(i) +'.csv'\n",
    "        filename2 = 'knn-dataset/trainLabels' + str(i) +'.csv'\n",
    "        \n",
    "        arr = []\n",
    "        with open(filename1, 'r') as csvFile:\n",
    "            reader = csv.reader(csvFile)\n",
    "            for row in reader:\n",
    "                for n in range(len(row)):\n",
    "                    row[n] = int(row[n])\n",
    "                arr.append(row)\n",
    "        csvFile.close()\n",
    "        trainData.append(arr)\n",
    "        \n",
    "        arr=[]\n",
    "        with open(filename2, 'r') as csvFile:\n",
    "            reader = csv.reader(csvFile)\n",
    "            for row in reader:\n",
    "                arr.append(int(row[0]))\n",
    "        csvFile.close()\n",
    "        trainLabel.append(arr)\n",
    "    with open('knn-dataset/testData.csv', 'r') as csvFile:\n",
    "        reader = csv.reader(csvFile)\n",
    "        for row in reader:\n",
    "            for n in range(len(row)):\n",
    "                row[n] = int(row[n])\n",
    "            testData.append(row)\n",
    "    csvFile.close()\n",
    "    \n",
    "    with open('knn-dataset/testLabels.csv', 'r') as csvFile:\n",
    "        reader = csv.reader(csvFile)\n",
    "        for row in reader:\n",
    "            testLabel.append(int(row[0]))\n",
    "    csvFile.close()\n",
    "    return trainData, trainLabel, testData, testLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy of mixtures of Guassian is 0.8909090909090909\n"
     ]
    }
   ],
   "source": [
    "TrainData, TrainLabels, TestData, TestLabels =readfile()\n",
    "TrainLabels = np.array(TrainLabels) - 5\n",
    "TestLabels = np.array(TestLabels) - 5\n",
    "trainLabel = TrainLabels\n",
    "testLabel = TestLabels\n",
    "trainData = np.reshape(TrainData, (1000, 64))\n",
    "trainLabel = np.reshape(trainLabel, (1000,))\n",
    "pi = np.sum(trainLabel)/len(trainLabel)\n",
    "indexArr1 = []\n",
    "indexArr2 = []\n",
    "for i in range(1000):\n",
    "    if trainLabel[i] == 0:\n",
    "        indexArr1.append(i)\n",
    "    else:\n",
    "        indexArr2.append(i)\n",
    "m1 = np.delete(trainData, indexArr2, 0)\n",
    "m2 = np.delete(trainData, indexArr1, 0)\n",
    "n1 = len(m1)\n",
    "n2 = len(m2)\n",
    "xy = [trainData[i] *trainLabel[i] for i in range(1000)]\n",
    "mu1 = np.sum(xy, axis = 0)/n1\n",
    "xy = [trainData[i] *(1-trainLabel[i]) for i in range(1000)]\n",
    "mu2 = np.sum(xy, axis = 0)/n2\n",
    "def helper(m):\n",
    "    x = (m - mu1)\n",
    "    return np.reshape(x, (64,1))@np.reshape(x, (1,64))\n",
    "s1 = np.sum([helper(m) for m in m1], axis = 0)/ n1\n",
    "s2 = np.sum([helper(m) for m in m2], axis = 0) / n2\n",
    "comatrix = n1/1000 * s1 + n2/1000 *s2\n",
    "x1 = [row - mu1 for row in trainData]\n",
    "x2 = [row - mu2 for row in trainData]\n",
    "def helper2(x, mu):\n",
    "    return -0.5 * np.reshape(x - mu, (1,64)) @ np.linalg.inv(comatrix)@ np.reshape(x - mu, (64,1))\n",
    "arr = []\n",
    "for x in TestData:\n",
    "    pr_x_c1 = math.exp(helper2(x, mu1)) * pi\n",
    "    pr_x_c2 = math.exp(helper2(x, mu2)) *(1-pi)\n",
    "    if(pr_x_c1 < pr_x_c2):\n",
    "        arr.append(0)\n",
    "    else:\n",
    "        arr.append(1)\n",
    "match = 0\n",
    "for i in range(110):\n",
    "    if arr[i] == testLabel[i]:\n",
    "        match +=1\n",
    "accuracy = match/110\n",
    "print(\"the accuracy of mixtures of Guassian is \"+ str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestData = np.c_[np.ones((110, 1)), TestData]\n",
    "## reshape the 1000 training data \n",
    "subtrainData = np.reshape(TrainData, (1000, 64))\n",
    "subtrainData = np.c_[np.ones((1000, 1)), subtrainData]##shape:(1000,65)\n",
    "subtrainLabel = np.reshape(TrainLabels, (1000,)) ## shape:(1000,)\n",
    "\n",
    "def logistic(z):\n",
    "    return 1/ (1+math.exp(0-z))\n",
    "\n",
    "accSet = []\n",
    "for eachlambda in range(0, 10000, 500):\n",
    "    accSum = 0\n",
    "    for fold in range(10):\n",
    "        \n",
    "        w = np.zeros(65)\n",
    "        ## extract 900 training data and reshape it.\n",
    "        subTrainData = np.delete(TrainData, fold, 0)\n",
    "        subTrainLabel = np.delete(TrainLabels, fold, 0)\n",
    "        subTrainData = np.reshape(subTrainData, (900, 64))\n",
    "        subTrainData = np.c_[np.ones((900, 1)), subTrainData]##shape:(900,65)\n",
    "        subTrainLabel = np.reshape(subTrainLabel, (900,)) ## shape:(900,)\n",
    "        \n",
    "        ## reshape the test data\n",
    "        subTestData = np.c_[np.ones((100, 1)), TrainData[fold]]\n",
    "        subTestLabel = TrainLabels[fold]\n",
    "        \n",
    "        def product(row):\n",
    "            pro =logistic(np.dot(subTrainData[row], w))\n",
    "            return pro\n",
    "        def cal_out(row):\n",
    "            if np.dot(w, subTestData[row]) > 0:\n",
    "                return 1\n",
    "            return 0\n",
    "        ## train weight w\n",
    "        for i in range(10):\n",
    "            Matrix =[(product(row) - subTrainLabel[row]) * subTrainData[row] for row in range(900)]\n",
    "            gradient = np.sum(Matrix, axis = 0) + eachlambda * w\n",
    "            \n",
    "            ##calculate hassian\n",
    "            im = np.identity(900)\n",
    "            rnn = [im[row] * product(row)*(1-product(row)) for row in range(900)]\n",
    "            h = subTrainData.T @ rnn @subTrainData + eachlambda * np.identity(65)\n",
    "            ## reweight\n",
    "            w -= np.linalg.inv(h) @ gradient\n",
    "        output = [cal_out(row) for row in range(100)]\n",
    "        def cal_match(row):\n",
    "            if output[row] == subTestLabel[row]:\n",
    "                return 1\n",
    "            return 0\n",
    "        match = np.sum([cal_match(row) for row in range(100)])\n",
    "        accuracy = match / 100\n",
    "        accSum += accuracy\n",
    "    aveAcc = accSum / 10\n",
    "    accSet.append(aveAcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy of logistic regression is 0.91\n"
     ]
    }
   ],
   "source": [
    "## Use lambda to train w on training set\n",
    "def product2(row):\n",
    "    pro =logistic(np.dot(subtrainData[row], w))\n",
    "    return pro\n",
    "w= np.zeros(65)\n",
    "for i in range(10):\n",
    "    Matrix =[(product2(row) - subtrainLabel[row]) * subtrainData[row] for row in range(900)]\n",
    "    gradient = np.sum(Matrix, axis = 0) + bestlambda * w\n",
    "\n",
    "    ##calculate hassian\n",
    "    im = np.identity(1000)\n",
    "    rnn = [im[row] * product2(row)*(1-product2(row)) for row in range(1000)]\n",
    "    h = subtrainData.T @ rnn @subtrainData + bestlambda * np.identity(65)\n",
    "    ## reweight\n",
    "    w -= np.linalg.inv(h) @ gradient\n",
    "def classifier(answer):\n",
    "    if answer >= 0:\n",
    "        return 1\n",
    "    return 0\n",
    "output = [classifier(np.dot(w, TestData[row])) for row in range(110)]\n",
    "match = 0\n",
    "for i in range(110):\n",
    "    if output[i] == TestLabels[i]:\n",
    "        match +=1\n",
    "Accuracy = match /110\n",
    "print(\"the accuracy of logistic regression is \"+ str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best lambda is 6500\n"
     ]
    }
   ],
   "source": [
    "plt.xlabel('lambda')\n",
    "plt.ylabel('accuracy')\n",
    "plt.plot(np.arange(0,10000, 500), accSet)\n",
    "plt.show()\n",
    "bestlambda = np.argmax(accSet) * 500\n",
    "print('the best lambda is '+ str(bestlambda))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brief discussion:\n",
    "The mixture gaussian has more parameters, since the mixture of Guassian has a joint distribution over inputs and ouputs; whereas logistic regression encodes a conditional distribution over the outputs given the inputs.\n",
    "The logistic regression requires more amount of computation than the mixture of Guassian since we need to do the gradient descent multiple times until it converges in logistic regression; for mixture of Guassian, we only need to implement the maximum likehood once. \n",
    "For accuracy, the logistic regression(0.91) gets higher accuracy than the mixture of Guassian(0.89).\n",
    "\n",
    "The result from Mixture of Gaussian and logistic regression has higher accuracy than the k nearest neighbours on both training set and the test set. The reason might be that k nearest neighbour is non-linear regression; whereas other two methods are linear regression. \n",
    "I think for the classification problem with small number of classes we use Mixture of Gaussian and logistic regression. For large number of classes, we use k nearest neighbours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This question is submitted using another pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification accuracy on 1000 training data point is 0.892\n"
     ]
    }
   ],
   "source": [
    "w = np.zeros(65)\n",
    "\n",
    "def logistic(z):\n",
    "    return 1/ (1+math.exp(0-z))\n",
    "def product(row):\n",
    "#             print(np.dot(subTrainData[row], w))\n",
    "#             print(w)\n",
    "    pro =logistic(np.dot(subtrainData[row], w))\n",
    "\n",
    "#             print(pro)\n",
    "    return pro\n",
    "## train weight w\n",
    "for i in range(10):\n",
    "    ##calculate gradient\n",
    "#             for i in range(900):\n",
    "#                 print(product(i) - subTrainLabel[i])\n",
    "#                 print(subTrainData[i])\n",
    "    Matrix =[(product(row) - subtrainLabel[row]) * subtrainData[row] for row in range(1000)]\n",
    "    gradient = np.sum(Matrix, axis = 0) \n",
    "#             print(gradient)\n",
    "\n",
    "    ##calculate hassian\n",
    "    im = np.identity(1000)\n",
    "    rnn = [im[row] * product(row)*(1-product(row)) for row in range(1000)]\n",
    "    h = subtrainData.T @ rnn @subtrainData \n",
    "    ## reweight\n",
    "    w -= np.linalg.inv(h) @ gradient \n",
    "    \n",
    "output = [classifier(np.dot(w, subtrainData[row])) for row in range(1000)]\n",
    "match = 0\n",
    "for i in range(1000):\n",
    "    if output[i] == subtrainLabel[i]:\n",
    "        match +=1\n",
    "Accuracy = match /1000\n",
    "print('The classification accuracy on 1000 training data point is '+ str(Accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I apply the logistics regression model on the training set of Q1 in above code. In the experiment, I applied 10 times newton methods until w converges. Finally, I got 89.2% accuracy. That means the logistic regression model can perfectly fit the q1 training data. \n",
    "\n",
    "Since logistic regression is a linear regression, the training set of q1 is linear seperable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
